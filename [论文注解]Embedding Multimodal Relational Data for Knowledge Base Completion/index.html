<!-- build time:Thu Jan 16 2020 11:36:25 GMT+0800 (China Standard Time) --><!DOCTYPE html><html class="theme-next gemini use-motion" lang="zh"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Consolas:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2"><link rel="stylesheet" href="/css/main.css?v=7.1.2"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png?v=7.1.2"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.2"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.2"><link rel="mask-icon" href="/images/logo.svg?v=7.1.2" color="#222"><script id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"7.1.2",sidebar:{position:"left",display:"post",offset:12,onmobile:!1,dimmer:!1},back2top:!0,back2top_sidebar:!1,fancybox:!1,fastclick:!1,lazyload:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><meta name="description" content="前言最近在https://github.com/pouyapez/mkbe上的DesGAN实验，因为不知道代码中中间需要的.npy文件从哪里产生，因此，在对对论文进行翻译的基础上进一步进行深层次的注解。Abstract在嵌入空间中表示实体和关系是关系数据机器学习的一种很好的方法然而，现有的方法主要集中于有限集合的实体之间的简单链接结构，而忽略了通常在知识库中使用的数据类型的多样性，例如文本、图像和"><meta name="keywords" content="知识嵌入,论文注解"><meta property="og:type" content="article"><meta property="og:title" content="【论文注解】Embedding Multimodal Relational Data for Knowledge Base Completion"><meta property="og:url" content="https://www.flyinghuster.com/[论文注解]Embedding Multimodal Relational Data for Knowledge Base Completion/index.html"><meta property="og:site_name" content="The Flying Huster"><meta property="og:description" content="前言最近在https://github.com/pouyapez/mkbe上的DesGAN实验，因为不知道代码中中间需要的.npy文件从哪里产生，因此，在对对论文进行翻译的基础上进一步进行深层次的注解。Abstract在嵌入空间中表示实体和关系是关系数据机器学习的一种很好的方法然而，现有的方法主要集中于有限集合的实体之间的简单链接结构，而忽略了通常在知识库中使用的数据类型的多样性，例如文本、图像和"><meta property="og:locale" content="zh"><meta property="og:updated_time" content="2019-11-16T03:52:27.310Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="【论文注解】Embedding Multimodal Relational Data for Knowledge Base Completion"><meta name="twitter:description" content="前言最近在https://github.com/pouyapez/mkbe上的DesGAN实验，因为不知道代码中中间需要的.npy文件从哪里产生，因此，在对对论文进行翻译的基础上进一步进行深层次的注解。Abstract在嵌入空间中表示实体和关系是关系数据机器学习的一种很好的方法然而，现有的方法主要集中于有限集合的实体之间的简单链接结构，而忽略了通常在知识库中使用的数据类型的多样性，例如文本、图像和"><link rel="alternate" href="/atom.xml" title="The Flying Huster" type="application/atom+xml"><link rel="canonical" href="https://www.flyinghuster.com/[论文注解]Embedding Multimodal Relational Data for Knowledge Base Completion/"><script id="page.configurations">CONFIG.page={sidebar:""}</script><title>【论文注解】Embedding Multimodal Relational Data for Knowledge Base Completion | The Flying Huster</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">The Flying Huster</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">记录科研生活的点点滴滴</h1></div><div class="site-nav-toggle"><button aria-label="Toggle navigation bar"><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>Home</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>Archives<span class="badge">40</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>Categories<span class="badge">24</span></a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>Tags<span class="badge">35</span></a></li><li class="menu-item menu-item-gallery"><a href="/gallery" rel="section"><i class="menu-item-icon fa fa-fw fa-photo"></i><br>Gallery</a></li><li class="menu-item menu-item-contact"><a href="/contact/" rel="section"><i class="menu-item-icon fa fa-fw fa-phone"></i><br>Contact</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>About</a></li><li class="menu-item menu-item-weekend-composer"><a href="https://www.weekendcomposer.com" rel="noopener" target="_blank"><i class="menu-item-icon fa fa-fw fa-music"></i><br>Weekend Composer</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>Search</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i> </span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"><input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header><a href="https://github.com/johannesliu" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewbox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="https://www.flyinghuster.com/[论文注解]Embedding Multimodal Relational Data for Knowledge Base Completion/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="刘中岳"><meta itemprop="description" content="飞翔的Huster"><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="The Flying Huster"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">【论文注解】Embedding Multimodal Relational Data for Knowledge Base Completion</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Created: 2019-11-08 09:42:13" itemprop="dateCreated datePublished" datetime="2019-11-08T09:42:13+08:00">2019-11-08</time> </span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">In</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/知识图谱/" itemprop="url" rel="index"><span itemprop="name">知识图谱</span></a></span> </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> Views: <span class="busuanzi-value" id="busuanzi_value_page_pv"></span></span><div class="post-symbolscount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">Symbols count in article: </span><span title="Symbols count in article">0</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">Reading time &asymp;</span> <span title="Reading time">1 mins.</span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>最近在<a href="https://github.com/pouyapez/mkbe" target="_blank" rel="noopener">https://github.com/pouyapez/mkbe</a>上的DesGAN实验，因为不知道代码中中间需要的.npy文件从哪里产生，因此，在对对论文进行翻译的基础上进一步进行深层次的注解。</p><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>在嵌入空间中表示实体和关系是关系数据机器学习的一种很好的方法然而，现有的方法主要集中于有限集合的实体之间的简单链接结构，而忽略了通常在知识库中使用的数据类型的多样性，例如文本、图像和数值。在本文中，我们提出了多模态知识库嵌入（MKBE），使用不同的神经编码器的各种观察到的数据，并结合它们与现有的关系模型，以了解嵌入的实体和多模态数据。此外，利用这些学习到的嵌入和不同的神经解码器，我们引入了一种新的多模态插补模型，从知识库中的信息生成缺失的多模态值，如文本和图像我们丰富现有的关系数据集，以创建两个新的基准，包含额外的信息，如文本描述和原始实体的图像。我们证明，我们的模型利用这一额外的信息，以有效地提供更准确的链路预测，实现国家的最先进的结果与现有方法相比，有5-7%的相当大的差距。此外，我们通过用户研究评估生成的多模态值的质量我们已经在<a href="https://github.com/pouyapez/mkbe" target="_blank" rel="noopener">https://github.com/pouyapez/mkbe</a> 上发布了数据集和模型的开源实现。</p><a id="more"></a><h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h1><p>知识库（knowledgebase，KB）是许多计算系统的重要组成部分，在搜索、结构化数据管理、推荐、问答和信息检索等领域有着广泛的应用然而，在不确定性条件下，知识库往往存在不完全性、条目噪声和推理效率低下等问题为了解决这些问题，学习关系知识表征一直是积极研究的重点（Bordes等人，2011、2013；Y ang等人，2015；Nickel等人，2016；Trouillon等人，2016；Dettmers等人，2018）这些方法通过从观察中学习每个实体和关系的固定的低维表示，对不确定性进行编码，并准确有效地推断缺失的事实，来表示由主体实体、关系和对象实体组成的关系三元组主题和对象实体来自知识库中出现的一组固定的、可枚举的实体。<br>然而，现实世界中的知识库除了这些直接链接之外，还包含各种各样的数据类型除了与固定实体集的关系外，知识库通常不仅包括数字属性（如年龄、日期、财务和地理信息），还包括文本属性（如名称、说明和标题/名称）和图像（剖面照片、旗帜、海报等）这些不同类型的数据可以作为知识库完成的额外证据发挥关键作用例如，文本描述和图像可以为一个人的年龄、职业和称号提供证据例如，在图1所示的多模态知识库中，图像有助于预测Carles Puyol的职业，而描述包含他的国籍不幸的是，将这些信息作为实体合并到现有的方法中是有挑战性的，因为它们通过枚举可能的值来分配每个实体不同的向量，并预测缺失的链接（或属性），如果实体来自一个小的可枚举集合，那么它们都是可能的。因此，关系建模的关键需求不仅仅是基于链路的KB完成视图，它不仅利用多模态信息来在现有实体之间进行更好的链路预测，而且能够生成丢失的多模式值。<br>在本文中，我们引入多模态知识库嵌入（MKBE）来建模包含各种数据类型（如链接、文本、图像、数值和分类值）的知识库我们建议使用神经编码器和解码器来替换任何基于嵌入的关系模型的初始层；我们将它们应用于DistMult（Y ang et al.，2015）和conv（Dettmers et al.，2018）具体来说，MKBE没有为每个实体学习一个不同的向量，而是使用枚举来预测链接，它包括以下扩展：（1）引入额外的神经编码器来嵌入关系模型用于预测链接的多模态证据类型（2）引入神经解码器，使用实体的嵌入来生成其多模态属性（如图像和文本）例如，当三元组的对象是图像时，我们使用CNN将其编码为固定长度的向量，而文本对象则使用基于RNN的序列编码器进行编码评分模块与基础关系模型保持一致；给定三元组的主语、关系和宾语的向量表示，我们使用DistMult或conv生成一个分数，指示三元组正确的概率在学习知识库表示之后，神经解码器使用实体嵌入来生成缺失的多模态属性，例如，从知识库中的结构化信息生成对人的描述这个统一的框架允许信息跨不同的关系类型（多模式或其他）流动，提供了更精确的关系数据建模。<br>我们对我们提出的方法在两个关系型知识库上进行了评估由于我们引入了多模式KB完成设置，我们提供了两个基准，通过扩展现有的Y AGO-10和MOVIELSEN-100K数据集来包括附加的关系，如文本描述、数字属性和实体的图像。我们证明，MKBE有效地利用附加信息来提高链路预测精度，在DistMult和conv评分函数的这些数据集上实现最新结果我们通过用户研究来评估解码器生成的多模态属性的质量，这些研究展示了解码器的真实性和信息内容，并给出了生成的文本和图像的示例。</p><h1 id="2-多模式知识库完成"><a href="#2-多模式知识库完成" class="headerlink" title="2. 多模式知识库完成"></a>2. 多模式知识库完成</h1><p>如前所述，KBs通常包含关于实体的不同类型的信息，包括链接、文本描述、分类属性、数值和图像在本节中，我们简要介绍了现有的关系嵌入方法，重点是使用不同的密集向量建模链接数据。然后，我们描述了将这些方法扩展到多模式设置的MKBE，即使用所有不同的信息来预测丢失的链接并输入丢失的属性来建模KB。</p><h2 id="2-1-链路预测背景"><a href="#2-1-链路预测背景" class="headerlink" title="2.1 链路预测背景"></a>2.1 链路预测背景</h2><p>知识库中的事实陈述用主语、关系和宾语的三元组hs、r、oi表示，其中s、o∈ζ是一组实体，r∈r是一组关系我们分别考虑了关系建模的两个目标：（1）训练一个机器学习模型，该模型可以对任何事实陈述的真实值进行评分；（2）预测实体之间缺少的链接在现有的方法中，一个打分函数为：x×r×r（有时为0，0），根据模型评估任何给定的事实是否为真。为了预测实体之间的链接，由于集合ζ小到可以枚举，丢失了形式hs，r，？通过枚举所有对象并使用Ψ对三元组进行评分（即假设结果实体来自已知集合）来识别i例如，在图1中，目标是预测Carles Puyol为巴塞罗那效力。<br>链接预测的许多最新进展使用了一种基于嵌入的方法；ζ中的每个实体和R中的关系被赋予不同的稠密向量，然后由Ψ来计算得分例如，在DistMult（Yang等人，2015）中，每个实体i映射到一个d维稠密向量（ei∈Rd），每个关系r映射到一个对角矩阵Rr∈Rd×d，因此，任何三重hs，r，oi的得分计算为Ψ（s，r，o）=et sRreo按照类似的思路，Conv（Dettmers et al.，2018）使用向量来表示实体和关系，e s，e o，r r∈Rd×1，然后，在e s and rr上应用CNN层后，将其与eo结合以得分三元组，即得分函数Ψ（s，r，o）是f（vec（f（[‘/es；’/rr*w]）eo其他关系嵌入方法在评分函数的设计上主要有所不同（Bordes等人，2013；Yang等人，2015；Nickel等人，2016；Trouillon等人，2016），但也有一个缺点，即为每个实体分配不同的向量，并假设可以枚举可能的对象实体在这项工作中，我们关注DistMult，因为它的简单、流行和高精度，而conv则因为它的最先进的结果。</p><h2 id="2-2-问题设置"><a href="#2-2-问题设置" class="headerlink" title="2.2 问题设置"></a>2.2 问题设置</h2><p>当面对以多模态数据形式出现的附加三元组时，链路预测的设置略有不同考虑一组所有可能的多模态对象，M，即可能的图像、文本、数值和分类值，以及多模态证据三元组，hs，r，o i，其中s∈ζ，r∈r，和o∈M。我们将多模态信息合并到KB中的目标保持不变：我们希望能够得到任何三元组hs，r，oi的真值其中o来自ζ（链路数据）或M（多模数据），并且能够预测丢失的值hs，r，？i可能来自于ζ或M（取决于r）对于图1中的示例，除了从多模态证据中预测Carles Puyol为巴塞罗那效力外，如果Carles Puyol的图像丢失，我们还希望为其生成图像。</p><p>该问题的现有方法假定对象和对象来自固定的实体集合ZEI，因此被视为该集合中的索引，其主要针对两个原因而失败于多模态设置。首先，为每个对象实体学习不同的向量并不适用于多模态值，因为它们将忽略多模态属性的实际内容例如，无法将训练期间学习到的向量归纳为可能出现在测试中的不可见值；这对于标准设置来说不是问题，因为假设在训练期间观察到了所有实体其次，为了预测丢失的多模态值，hs，r，？枚举是不可能的，因为搜索空间可能是无限的（或者至少是难以搜索的）。</p><h2 id="2-3-多模式KB嵌入（MKBE）"><a href="#2-3-多模式KB嵌入（MKBE）" class="headerlink" title="2.3 多模式KB嵌入（MKBE）"></a>2.3 多模式KB嵌入（MKBE）</h2><p>为了将这样的多模态对象集成到现有的关系模型中，例如，我们建议学习这些类型的数据的嵌入。我们利用深度学习的最新进展来构造这些对象的编码器来表示它们，本质上为任何对象值提供了一个嵌入的eo。</p><p>总体目标保持不变：模型需要利用不同数据类型中所有观察到的主题、对象和关系，以估计任何事实hs、r、oi是否成立我们在图2a中给出了一个包含Y个AGO实体的知识库的MKBE实例。对于任何三元组hs、r、oi，我们使用直接查找嵌入主题（Carles Puyol）和关系（例如playsFor、wasBornOn或playsFor）对于对象，根据域（分别为索引、字符串、数字或图像），我们使用适当的编码器来计算其嵌入eo在DistMult和conver中，这些嵌入用于计算三元组的分数。</p><p>通过这些神经编码器，该模型可以利用多模态对象的信息量来预测对象来自ζ的丢失链路，然而，学习M中对象的嵌入不足以产生丢失的多模态值，即hs、r、，？因此，我们引入了一组神经解码器D:ζ×R→M，它使用实体嵌入来生成多模态值图2b描绘了我们估算缺失值模型的概要。我们将在第2.5节描述这些解码器。</p><h2 id="2-4-编码多模数据"><a href="#2-4-编码多模数据" class="headerlink" title="2.4 编码多模数据"></a>2.4 编码多模数据</h2><p>这里我们描述了我们用于多模态对象的编码器图2a提供了一个简单的MKBE示例，如图所示，我们使用不同的编码器嵌入每个特定的数据类型。<br>结构化知识是以hs，r，oi形式存在的三元组信息为了将主题实体s和关系r表示为独立的嵌入向量（如前所述），我们将它们的一个热编码通过密集层此外，对于对象实体是分类的情况，我们通过最近引入的selu激活（Klambauer et al.，2017）将其嵌入到密集层中，节点数与嵌入空间维度相同。<br>实数形式的数字对象可以提供有用的信息源，而且通常很容易获得在标准化输入之后，我们使用一个前馈层来嵌入数字（事实上，我们将数字从R→Rd投影到更高的维空间）值得注意的是，现有的方法将数字视为不同的实体，例如，学习数字39和40的独立向量，依靠数据来了解这些值彼此相似。<br>文本由于文本可以用来存储各种不同类型的信息，例如名称和段落长的描述，我们根据所涉及字符串的长度创建不同的编码器对于相当短的属性，例如名称和标题，我们使用基于字符的堆叠双向GRU对它们进行编码，类似于V erga等人（2016），使用顶层的最终输出作为字符串的表示对于更长的字符串，例如由多个句子组成的实体的详细描述，我们将它们视为一个单词序列，并在单词嵌入上使用CNN，类似于Francis Landau等人（2016年），以了解这些价值观的嵌入这两个编码器提供了一个固定长度的编码，已被证明是多个任务字符串的精确语义表示（Dos Santos和Gatti，2014）。<br>图像还可以为实体建模提供有用的证据例如，我们可以从人的图像（利维和Hassner，2015）中提取人的细节，例如性别、年龄、工作等，或者从地图图像（Wyand等人，2016）的位置信息，如它的近似坐标、相邻位置和大小。多种模型被用来紧凑地表示图像中的语义信息，并成功地应用于图像分类、字幕（Karpathy and Fei Fei，2015）和问答（Yang et al.，2016）等任务为了嵌入图像，使编码代表这样的语义信息，我们使用Imagenet上VGG预训练网络的最后一个隐藏层（Simonyan和Zisserman，2015），然后使用紧致双线性池（Gao等人，2016）来获得图像的嵌入。<br>训练我们遵循Dettmers等人的设置（2018）包含二元交叉熵损失，对流和DisMult评分均无负采样特别是，对于给定的subjectrelation对（s，r），我们使用一个二进制标签向量ts，rover all entities，指示在训练期间是否观察到hs，r，oi进一步，我们用ps，r o来表示任何三元组hs，r，oi的模型的真值概率，用s，r，o来表示因此，二元交叉熵损失定义为：<br>对于多模态三元组，我们也使用相同的损失，只是总和仅限于相同模态的对象，即对于实体及其文本描述，ts，ris是训练期间观察到的所有描述的一个热向量。</p><h2 id="2-5-解码多模数据"><a href="#2-5-解码多模数据" class="headerlink" title="2.5 解码多模数据"></a>2.5 解码多模数据</h2><p>在这里，我们描述了用于从实体的嵌入生成多模态值的解码器多模输入模型如图2b所示，该模型使用不同的神经解码器生成缺失属性（更多细节见补充材料）。<br>为了恢复缺失的数字和分类数据，如日期、性别和职业，我们在实体嵌入上使用简单的前馈网络来预测缺失的属性换句话说，我们在问模型，如果一个实体的实际出生日期不在KB中，那么考虑到其余的关系信息，最有可能的日期是什么这些解码器使用第2.4节中的嵌入进行训练，具有适当的损失（RMSE表示数值，交叉熵表示类别）。<br>文本一些方法考虑了生成性对抗网络（GANs）来生成语法和语言上连贯的句子（Y u et al.，2017；Rajeswar et al.，2017；Guo et al.，2017）在这项工作中，我们使用逆正则化自动编码器（ARAE）（Zhao等人，2017）来训练从连续码解码文本的生成器，但是，我们不使用随机噪声向量z，而是将生成器设置在实体嵌入上。<br>图像类似于文本恢复，为了找到处理图像，我们使用条件GAN结构具体来说，我们将BE-GAN（Berthelot et al.，2017）结构与pix2pix-GAN（Isola et al.，2017）模型相结合，生成高质量的图像，使生成器在知识库表示中嵌入实体。</p><h1 id="3-相关工作"><a href="#3-相关工作" class="headerlink" title="3. 相关工作"></a>3. 相关工作</h1><p>关于使用低维表示对知识库建模的文献非常丰富，不同的是用于对三元组进行评分的运算符特别是，他们使用矩阵和张量乘法（Nickel等人，2011年；Y ang等人，2015年；Socher等人，2013年）、欧几里德距离（Bordes等人，2013年；Wang等人，2014年；Lin等人，2015年）、循环相关（Nickel等人，2016年）或Hermitian点积（Trouillon等人，2016年）作为评分函数然而，所有这些方法的对象都是一组固定的实体，即它们只嵌入实体之间的结构化链接这里，我们在编码组件中将不同类型的信息（文本、数值、图像等）视为关系三元组。<br>许多方法利用额外类型的信息作为实体的观察特征，通过合并、连接或平均实体及其特征来计算其嵌入，例如数值（Garcia Duran和Niepert2017年）（我们使用这项工作中的KBLN将其与仅使用数值作为额外属性的方法进行比较）、图像（Xie等人，2017年；Oenoro Rubio等人，2017年）（我们使用第一项工作中的IKRL将其与仅使用图像作为额外属性的方法进行比较）、文本（McAuley和Leskovec，2013年；Zhong等人，2015年；Toutanova等人，2015年2016；Xie等人，2016；Tu等人，2017），以及文本和图像的组合（Sergieh等人，2018）此外，V erga等人（2016）解决多语言关系提取任务，通过将不带注释的原始文本作为额外特征，并使用矩阵分解联合嵌入知识库和文本关系，获得通用模式（Riedel等人，2013）除了将额外信息视为特征外，图嵌入方法（Schlichtkrull等人，2017；Kipf和Welling，2016）在编码时考虑观察到的属性，以实现更精确的嵌入。<br>MKBE与上述方法的区别在于三个方面：（1）我们首先在一个统一的模型中使用不同类型的信息，（2）我们将这些不同类型的信息（数字、文本、图像）视为结构化知识的关系三元组，而不是预先确定的特征，即知识库的一级公民而不是辅助特征，（3）我们的模型表示它们中的不确定性，支持缺失值并促进缺失值的恢复。</p><h1 id="4-评价基准"><a href="#4-评价基准" class="headerlink" title="4. 评价基准"></a>4. 评价基准</h1><p>为了评估我们的多模态关系嵌入方法的性能，我们通过扩展现有的数据集来提供两个新的基准。表1提供了这些数据集的统计信息。<br>MovieLens-100k数据集（Harper和Konstan，2016）是推荐系统中一个流行的基准，用于预测具有上下文特征的用户评分，包含1700部电影中的约1000名用户MovieLens已经包含了关于职业、性别、邮政编码、用户年龄、类型、发行日期和电影标题的丰富关系数据我们用从TMDB（<a href="https://www.themoviedb.org/）收集的电影海报来补充这些数据我们将5点评分作为5种不同的关系，采用KB三重格式，即huser，r=5，moviei，并在引入其他关系的情况下对评分预测进行评估。" target="_blank" rel="noopener">https://www.themoviedb.org/）收集的电影海报来补充这些数据我们将5点评分作为5种不同的关系，采用KB三重格式，即huser，r=5，moviei，并在引入其他关系的情况下对评分预测进行评估。</a><br>Y AGO-10尽管MovieLens有多种数据类型，但它仍然很小，而且是在一个专门的域上我们还考虑了第二个数据集，该数据集更适合于知识图的完成，并且在链路预测中很受欢迎，即Y AGO3-10知识图（Suchanek等人，2007；Nickel等人，2012）该图由大约120000个实体（如人员、位置和组织）和37个关系（如亲属关系、工作关系和居住关系）组成，因此更接近于传统的信息提取目标我们使用DBpedia提供的文本描述（作为附加关系）和与每个实体相关联的图像（用于一半实体）扩展了这个数据集（Lehmann等人，2015）我们还包括一些附加关系，比如wasBornOnDate，它们的值是日期。</p><h1 id="5-实验结果"><a href="#5-实验结果" class="headerlink" title="5. 实验结果"></a>5. 实验结果</h1><p>在这一部分中，我们首先通过比较DistMult和conver在各种任务中的使用情况来评估MKBE利用多模态信息的能力然后，以恢复丢失的多模态值（文本、图像和数值）为动机，我们检验了模型的生成能力补充材料中提供了超参数和模型配置的详细信息，可在<a href="https://github.com/pouyapez/mkbe上获取源代码和用于再现结果的数据集。" target="_blank" rel="noopener">https://github.com/pouyapez/mkbe上获取源代码和用于再现结果的数据集。</a></p><h2 id="5-1-链路预测"><a href="#5-1-链路预测" class="headerlink" title="5.1 链路预测"></a>5.1 链路预测</h2><p>在本节中，我们将评估MKBE在链路预测任务中的能力目标是计算MRR和Hits@metric（排名评估），通过对所有实体进行排名并计算正确实体的排名，从测试数据集中的三个实体中恢复丢失的实体与前面的工作类似，这里我们专注于在过滤设置中提供结果，也就是说，我们只将测试数据中的三元组与从未出现在列车或测试数据集中的三元组进行比较。<br>MovieLens-100k我们使用评分作为用户和电影之间的关系来训练模型我们对电影标题使用字符级GRU，对年龄、邮政编码和发行日期使用单独的前馈网络，最后，我们在海报上使用VGG网络（对于使用密集层的其他关系）表2显示了当测试数据仅由三个评级组成时，MovieLens的链接（评级）预测估值我们通过对表示评级而不是对象实体的五个关系进行排序来计算度量我们将使用分级的模型标记为R，电影属性标记为M，用户属性标记为U，电影标题标记为T，海报标记为P如图所示，R+M+U+T模型的性能优于其他模型，但存在相当大的差距，表明了合并额外信息的重要性基线的命中率为1，匹配现有的推荐系统（Guime*等人，2012）。从这些结果中，我们可以看出，与海报相比，模特们从标题中获益更多。<br>YAGO-10我们的Y AGO数据集的链接预测结果如表3所示我们使用结构化信息标记模型为S，实体描述为D，数字信息标记为N，实体图像标记为I。我们发现编码所有类型信息的模型比其他模型表现得更好，这表明该模型在利用额外信息方面是有效的另一方面，只使用文本的模型性能次优，这表明实体描述包含的信息比其他模型更多值得注意的是，模型S的性能优于所有其他模型，这表明了使用不同数据类型以获得更高精度的重要性这一观察结果在DistMult和conv上都是一致的，conv上获得的结果是该数据集的新技术状态（与Dettmers等人相比）（2018年）。此外，我们还实现了KBLN（Garcia Duran和Niepert，2017）和IKRL（Xie等人，2017），将它们与我们的S+N和S+I模型进行比较我们的模型优于这些方法，部分原因是这两种方法在每个三元组中的主语和宾语都需要相同的多模态属性。<br>关系分解我们对Y AGO数据集执行额外的分析，以便使用表5：预测Y AGO（日期）和MovieLens（流派）的数量和类别，使用具有不同信息访问权限的模型，更深入地了解我们模型的性能。<br>对流法表4比较了我们的模型中一些最常见的关系如图所示，包含文本描述的模型对于关联和关系的播放有显著的好处，因为这些信息经常出现在文本中此外，图像对于hassegend和isMarriedTo是有用的，而对于不相关的关系，数字（日期）比图像更有效。</p><h2 id="5-2-输入多模态属性"><a href="#5-2-输入多模态属性" class="headerlink" title="5.2 输入多模态属性"></a>5.2 输入多模态属性</h2><p>在这里，我们提出了一个关于输入多模态属性（文本，图像和数字）的评估。<br>数值和分类表5a显示了预测数据中缺失数值的性能，通过保留10%的数据进行评估我们只考虑最近于公元1000年的数值（日期），以关注更相关的实体除了神经解码器，我们还通过考虑区间[10002017]中所有1017个选项来训练基于搜索的解码器，并且对于测试数据中的每三个选项，找到模型得分最高的数字；我们使用这个值来计算RMSE。我们可以看到，在这两个数据集中，所有信息都优于其他方法演示MKBE能够利用不同的多模态值来模拟数值信息此外，神经解码器的性能优于基于搜索的解码器，显示了正确解码器的重要性，即使对于有限的可枚举集也是如此同样，表5b显示了10%heldout MovieLens数据集的类型预测精度同样，使用所有信息的模型优于其他方法。<br>电影片名的生成，我们随机选取其中200个作为测试，100个作为验证，其余的作为训练数据这里的目标是使用前面提到的GAN结构在测试数据中生成电影的标题为了评估我们的结果，我们在Amazon Mechanical Turk（AMT）上进行了一个人体实验，询问参与者两个问题：（1）他们是否发现电影标题是真实的，以及（2）四种类型中哪一种最适合给定的标题我们将30部电影分别视为参考片名，将仅由收视率产生的假片名视为条件数据，并将所有信息视为假片名此外，每个问题都是针对3名参与者提出的，在大多数选择中计算出的结果如表6所示使用所有信息生成的伪标题与参考电影标题更为相似，这表明可以访问更多信息的嵌入程序可以有效地生成更高质量的标题。<br>YAGO Descriptions此处的目标是从实体的嵌入生成描述文本由于最初的描述可能很长，我们考虑少于30个标记的第一个句子，得到96405个句子我们随机考虑其中3000个作为测试，3000个作为验证，剩下的作为解码器的训练数据为了评估生成的描述的质量，以及它们是否适合实体，我们进行了一项用户研究，询问参与者是否能够从描述中猜测句子的真实性和主题实体的职业（艺人、运动员或政治家）、性别和年龄（35岁以上或以下）我们为每一个模型提供30个例子，从3个参与者提出每个问题，并计算多数票的准确性表7所示的结果表明，这些模型在向用户通知实体信息方面具有相当的能力，而且，从能够访问更多信息的嵌入生成的描述优于仅使用结构化数据的模型表8提供了生成描述的示例（除了用户研究的屏幕截图外，补充材料中还提供了更多生成描述的示例和MovieLens标题）。<br>在这里，我们评估由人类嵌入实体生成的图像的质量（31520，分为train/text）类似于描述，我们进行了一项研究，要求用户猜测图像的真实性以及主题的职业、性别和年龄我们为每个模型提供了30个例子，从3个参与者中提出每个问题，并使用多数选择。<br>表7的结果表明，基于所有信息的嵌入生成的图像对于性别和职业更为准确从图片中猜测年龄是很困难的，因为DBpedia上的图片可能与人的年龄不符，即一些年长的名人有他们年轻时的照片生成图像的示例如表9所示。</p><h1 id="6-讨论和限制"><a href="#6-讨论和限制" class="headerlink" title="6. 讨论和限制"></a>6. 讨论和限制</h1><p>关于知识库嵌入方法的一个重要问题是它们的可伸缩性虽然大KBS是所有基于嵌入的链路预测技术的问题，但MKBE并不比现有的更差，因为我们将多模式信息视为额外的三元组。具体而言，尽管多模态编码器/解码器比现有的关系模型训练更昂贵，但成本仍然是附加的，因为我们正在有效地增加训练数据集的大小。<br>除了可伸缩性之外，在使用多模态属性时几乎没有其他挑战尽管多模态证据提供了更多的信息，但是对于预测知识库的关系结构来说，这些额外数据的哪些部分是有用的并不明显，而且模型容易过度拟合MKBE基于对特定模式有效的神经编码器和解码器的设计，结果表明它能够有效地利用信息然而，仍然需要进一步研究以更有效和准确的方式捕获多模态属性的模型。<br>由于我们的输入多模态属性模型是基于GAN结构和从KB表示中学习到的嵌入，生成的属性直接受到GAN模型的能力和嵌入向量中信息量的限制尽管我们生成的属性传达了对应实体的几个方面由于我们的数据集的大小（我们的图像和文本数据集都比现有文本/图像生殖器文献中的公共数据集小），以及通过嵌入向量捕获的信息量（知识图是稀疏的），它们的质量远不是理想的。在未来，我们希望（1）扩展多模态数据集，使其具有更多的属性（使用更多Y之前的实体）；（2）不要使用学习的嵌入来生成缺少的属性，而是直接使用知识图来生成。</p><h1 id="7-结论"><a href="#7-结论" class="headerlink" title="7. 结论"></a>7. 结论</h1><p>由于需要利用文本和图像等多种信息源来实现更精确的链接预测，我们提出了一种新的多模态关系学习的神经方法我们介绍了一个链路预测模型MKBE，该模型包括（1）组合编码组件，用于联合学习实体和多模态嵌入，以对每个实体可用的信息进行编码，以及（2）使用这些实体嵌入来输入丢失的多模态值的经对手训练的解码组件我们丰富的两个现有的数据集，Y-AGO-10和MOVIELSEN-100K，与多模态信息引入基准。我们表明，MKBE，相比现有的链路预测器DistMult和CONVE，可以实现更高的准确性，链路预测利用多模态证据。此外，我们还证明了MKBE有效地结合了相关信息来生成高质量的多模态属性，如图像和文本我们已经在<a href="https://github.com/pouyapez/mkbe上发布了数据集和模型的开源实现。" target="_blank" rel="noopener">https://github.com/pouyapez/mkbe上发布了数据集和模型的开源实现。</a></p></div><footer class="post-footer"><div class="post-tags"><a href="/tags/知识嵌入/" rel="tag"># 知识嵌入</a> <a href="/tags/论文注解/" rel="tag"># 论文注解</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/现代计算机网络课程笔记（二）/" rel="next" title="现代计算机网络课程笔记（二）"><i class="fa fa-chevron-left"></i> 现代计算机网络课程笔记（二）</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/现代计算机网络课程笔记（三）/" rel="prev" title="现代计算机网络课程笔记（三）">现代计算机网络课程笔记（三） <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">Table of Contents</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">Overview</li></ul><div class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="刘中岳"><p class="site-author-name" itemprop="name">刘中岳</p><div class="site-description motion-element" itemprop="description">飞翔的Huster</div></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">40</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">14</span> <span class="site-state-item-name">categories</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">23</span> <span class="site-state-item-name">tags</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/johannesliu" title="GitHub &rarr; https://github.com/johannesliu" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a> </span><span class="links-of-author-item"><a href="mailto:iexkliu@gmail.com" title="E-Mail &rarr; mailto:iexkliu@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i></a> </span><span class="links-of-author-item"><a href="https://plus.google.com/iexkliu" title="Google &rarr; https://plus.google.com/iexkliu" rel="noopener" target="_blank"><i class="fa fa-fw fa-google"></i></a> </span><span class="links-of-author-item"><a href="https://twitter.com/iexkliu" title="Twitter &rarr; https://twitter.com/iexkliu" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i></a> </span><span class="links-of-author-item"><a href="https://www.facebook.com/iexkliu" title="FB Page &rarr; https://www.facebook.com/iexkliu" rel="noopener" target="_blank"><i class="fa fa-fw fa-facebook"></i></a> </span><span class="links-of-author-item"><a href="https://youtube.com/iexkliu" title="YouTube &rarr; https://youtube.com/iexkliu" rel="noopener" target="_blank"><i class="fa fa-fw fa-youtube"></i></a></span></div><div class="cc-license motion-element" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div><div><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="298" height="52" src="//music.163.com/outchain/player?type=2&id=3192251305&auto=1&height=32"></iframe></div></div></div><div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#前言"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Abstract"><span class="nav-number">2.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-介绍"><span class="nav-number">3.</span> <span class="nav-text">1. 介绍</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-多模式知识库完成"><span class="nav-number">4.</span> <span class="nav-text">2. 多模式知识库完成</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-链路预测背景"><span class="nav-number">4.1.</span> <span class="nav-text">2.1 链路预测背景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-问题设置"><span class="nav-number">4.2.</span> <span class="nav-text">2.2 问题设置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-多模式KB嵌入（MKBE）"><span class="nav-number">4.3.</span> <span class="nav-text">2.3 多模式KB嵌入（MKBE）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-4-编码多模数据"><span class="nav-number">4.4.</span> <span class="nav-text">2.4 编码多模数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-5-解码多模数据"><span class="nav-number">4.5.</span> <span class="nav-text">2.5 解码多模数据</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-相关工作"><span class="nav-number">5.</span> <span class="nav-text">3. 相关工作</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-评价基准"><span class="nav-number">6.</span> <span class="nav-text">4. 评价基准</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-实验结果"><span class="nav-number">7.</span> <span class="nav-text">5. 实验结果</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-链路预测"><span class="nav-number">7.1.</span> <span class="nav-text">5.1 链路预测</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-输入多模态属性"><span class="nav-number">7.2.</span> <span class="nav-text">5.2 输入多模态属性</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-讨论和限制"><span class="nav-number">8.</span> <span class="nav-text">6. 讨论和限制</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7-结论"><span class="nav-number">9.</span> <span class="nav-text">7. 结论</span></a></li></ol></div></div></div></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright"><span style="padding-left:25px;background:url(https://static.dy208.cn/o_1dfilp8ruo521thr1hvf18ji17soa.png) no-repeat left center" rel="nofollow"><a href="http://www.beian.miit.gov.cn" rel="noopener" target="_blank">豫ICP备19040049号-1| </a><span style="padding-left:25px;background:url(https://www.return520.com/images/beian.png) no-repeat left center" rel="nofollow"><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=" rel="noopener" target="_blank">豫公网安备 41132402411642号 </a>&copy; 2019 - <span itemprop="copyrightYear">2020</span> <span class="with-love" id="animate"><i class="fa fa-at"></i> </span><span class="author" itemprop="copyrightHolder">刘中岳</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span class="post-meta-item-text">Symbols count total: </span><span title="Symbols count total">114k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span class="post-meta-item-text">Reading time total &asymp;</span> <span title="Reading time total">1:23</span></span></span></div><div><span id="runtime_span"></span><script type="text/javascript">function show_runtime(){window.setTimeout("show_runtime()",1e3),X=new Date("11/08/2019 11:10:17"),Y=new Date,T=Y.getTime()-X.getTime(),M=864e5,a=T/M,A=Math.floor(a),b=24*(a-A),B=Math.floor(b),c=60*(b-B),C=Math.floor(60*(b-B)),D=Math.floor(60*(c-C)),runtime_span.innerHTML="本站勉强运行: "+A+"天"+B+"小时"+C+"分"+D+"秒"}show_runtime()</script></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="Total Visitors"><span class="busuanzi-value" id="busuanzi_value_site_uv"></span> </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="Total Views"><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span></div><script>!function(){var e=document.createElement("script");e.src="//tajs.qq.com/stats?sId=66487025";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><div style="display:none"><script src="//s95.cnzz.com/z_stat.php?id=1278185485&web_id=1278185485"></script></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div><script>"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script color="255,0,255" opacity="0.8" zindex="-1" count="200" src="//cdn.jsdelivr.net/gh/theme-next/theme-next-canvas-nest@1/canvas-nest.min.js"></script><script src="/lib/jquery/index.js?v=2.1.3"></script><script src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script src="/js/utils.js?v=7.1.2"></script><script src="/js/motion.js?v=7.1.2"></script><script src="/js/affix.js?v=7.1.2"></script><script src="/js/schemes/pisces.js?v=7.1.2"></script><script src="/js/scrollspy.js?v=7.1.2"></script><script src="/js/post-details.js?v=7.1.2"></script><script src="/js/next-boot.js?v=7.1.2"></script><script>function proceedsearch(){$("body").append('<div class="search-popup-overlay local-search-pop-overlay"></div>').css("overflow","hidden"),$(".search-popup-overlay").click(onPopupClose),$(".popup").toggle();var e=$("#local-search-input");e.attr("autocapitalize","none"),e.attr("autocorrect","off"),e.focus()}var isfetched=!1,isXml=!0,search_path="search.xml";0===search_path.length?search_path="search.xml":/json$/i.test(search_path)&&(isXml=!1);var path="/"+search_path,onPopupClose=function(e){$(".popup").hide(),$("#local-search-input").val(""),$(".search-result-list").remove(),$("#no-result").remove(),$(".local-search-pop-overlay").remove(),$("body").css("overflow","")},searchFunc=function(e,t,o){"use strict";$("body").append('<div class="search-popup-overlay local-search-pop-overlay"><div id="search-loading-icon"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div>').css("overflow","hidden"),$("#search-loading-icon").css("margin","20% auto 0 auto").css("text-align","center"),$.ajax({url:e,dataType:isXml?"xml":"json",async:!0,success:function(e){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var n=isXml?$("entry",e).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get():e,r=document.getElementById(t),s=document.getElementById(o),a=function(){var e=r.value.trim().toLowerCase(),t=e.split(/[\s\-]+/);t.length>1&&t.push(e);var o=[];if(e.length>0&&n.forEach(function(n){function r(t,o,n,r){for(var s=r[r.length-1],a=s.position,i=s.word,l=[],h=0;a+i.length<=n&&0!=r.length;){i===e&&h++,l.push({position:a,length:i.length});var p=a+i.length;for(r.pop();0!=r.length&&(s=r[r.length-1],a=s.position,i=s.word,p>a);)r.pop()}return c+=h,{hits:l,start:o,end:n,searchTextCount:h}}function s(e,t){var o="",n=t.start;return t.hits.forEach(function(t){o+=e.substring(n,t.position);var r=t.position+t.length;o+='<b class="search-keyword">'+e.substring(t.position,r)+"</b>",n=r}),o+=e.substring(n,t.end)}var a=!1,i=0,c=0,l=n.title.trim(),h=l.toLowerCase(),p=n.content.trim().replace(/<[^>]+>/g,""),u=p.toLowerCase(),f=decodeURIComponent(n.url).replace(/\/{2,}/g,"/"),d=[],g=[];if(""!=l&&(t.forEach(function(e){function t(e,t,o){var n=e.length;if(0===n)return[];var r=0,s=[],a=[];for(o||(t=t.toLowerCase(),e=e.toLowerCase());(s=t.indexOf(e,r))>-1;)a.push({position:s,word:e}),r=s+n;return a}d=d.concat(t(e,h,!1)),g=g.concat(t(e,u,!1))}),(d.length>0||g.length>0)&&(a=!0,i=d.length+g.length)),a){[d,g].forEach(function(e){e.sort(function(e,t){return t.position!==e.position?t.position-e.position:e.word.length-t.word.length})});var v=[];0!=d.length&&v.push(r(l,0,l.length,d));for(var $=[];0!=g.length;){var C=g[g.length-1],m=C.position,x=C.word,w=m-20,y=m+80;w<0&&(w=0),y<m+x.length&&(y=m+x.length),y>p.length&&(y=p.length),$.push(r(p,w,y,g))}$.sort(function(e,t){return e.searchTextCount!==t.searchTextCount?t.searchTextCount-e.searchTextCount:e.hits.length!==t.hits.length?t.hits.length-e.hits.length:e.start-t.start});var T=parseInt("1");T>=0&&($=$.slice(0,T));var b="";b+=0!=v.length?"<li><a href='"+f+"' class='search-result-title'>"+s(l,v[0])+"</a>":"<li><a href='"+f+"' class='search-result-title'>"+l+"</a>",$.forEach(function(e){b+="<a href='"+f+'\'><p class="search-result">'+s(p,e)+"...</p></a>"}),b+="</li>",o.push({item:b,searchTextCount:c,hitCount:i,id:o.length})}}),1===t.length&&""===t[0])s.innerHTML='<div id="no-result"><i class="fa fa-search fa-5x"></i></div>';else if(0===o.length)s.innerHTML='<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>';else{o.sort(function(e,t){return e.searchTextCount!==t.searchTextCount?t.searchTextCount-e.searchTextCount:e.hitCount!==t.hitCount?t.hitCount-e.hitCount:t.id-e.id});var a='<ul class="search-result-list">';o.forEach(function(e){a+=e.item}),a+="</ul>",s.innerHTML=a}};r.addEventListener("input",a),$(".local-search-pop-overlay").remove(),$("body").css("overflow",""),proceedsearch()}})};$(".popup-trigger").click(function(e){e.stopPropagation(),isfetched===!1?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(onPopupClose),$(".popup").click(function(e){e.stopPropagation()}),$(document).on("keyup",function(e){var t=27===e.which&&$(".search-popup").is(":visible");t&&onPopupClose()})</script><script>$("body").find("div.pdf").length&&$.ajax({type:"GET",url:"//cdn.jsdelivr.net/npm/pdfobject@2/pdfobject.min.js",dataType:"script",cache:!0,success:function(){$("body").find("div.pdf").each(function(e,t){PDFObject.embed($(t).attr("target"),$(t),{pdfOpenParams:{navpanes:0,toolbar:0,statusbar:0,pagemode:"thumbs",view:"FitH"},PDFJS_URL:"/lib/pdf/web/viewer.html",height:$(t).attr("height")||"500px"})})}})</script><script>$(".highlight").not(".gist .highlight").each(function(e,t){var n=$("<div>").addClass("highlight-wrap");$(t).after(n),n.append($("<button>").addClass("copy-btn").append("Copy").on("click",function(e){var t=$(this).parent().find(".code").find(".line").map(function(e,t){return $(t).text()}).toArray().join("\n"),n=document.createElement("textarea"),o=window.pageYOffset||document.documentElement.scrollTop;n.style.top=o+"px",n.style.position="absolute",n.style.opacity="0",n.readOnly=!0,n.value=t,document.body.appendChild(n);const a=document.getSelection(),i=a.rangeCount>0&&a.getRangeAt(0);n.select(),n.setSelectionRange(0,t.length),n.readOnly=!1;var d=document.execCommand("copy");d?$(this).text("Copied"):$(this).text("Copy failed"),n.blur(),$(this).blur(),i&&(a.removeAllRanges(),a.addRange(i))})).on("mouseleave",function(e){var t=$(this).find(".copy-btn");setTimeout(function(){t.text("Copy")},300)}).append(t)})</script></body></html><!-- rebuild by neat -->